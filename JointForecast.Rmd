---
title: "03B_initial_forecast_LE"
author: "Nia Bartolucci; Cameron Reimer; Kangjoon Cho; Zhenpeng Zuo"
date: "4/14/2021"
output: html_document
---

```{r}
## Package check and load

#install.packages("tidyverse")
#install.packages("readr")
library(tidyverse)
library(readr)
library(rjags)
library(rnoaa)
library(daymetr)
#library(ecoforecastR)
source("/Users/niabartolucci/Dropbox/My Mac (Niaâ€™s MacBook Pro)/Desktop/Classes Spring 2021/Ecological Forecasting/EF_Activities/ecoforecastR/R/utils.R")

#remotes::install_github("EcoForecast/ecoforecastR",force=TRUE)
```

```{r}
# If you need run data download
###source('01A_Targetdownload.R')

# definition for PATH
basePath <- getwd() 
graphPath <- paste0(basePath,"/graph/")
dataPath <- paste0(basePath,"/data/")

# load the data file [30 min Target data]
loadFilename <- sprintf("%s.Rdata","Target_30min")
loadFilename <- paste(dataPath, loadFilename, sep="", collapse = NULL)
load(file = loadFilename)

loadFilename <- sprintf("%s.Rdata","Radiance")
loadFilename <- paste(dataPath, loadFilename, sep="", collapse = NULL)
load(file = loadFilename)

swlw_2 = swlw[["SLRNR_30min"]]
rm(swlw)
swlw = swlw_2
rm(swlw_2)

# define site names
site_names <- c("BART","KONZ","OSBS","SRER")

```

```{r}
##subset
Target_30min_BART = subset(Target_30min, siteID == 'BART' & time >= as.POSIXct('2020-03-01 00:00', tz="UTC") & 
                                                                time < as.POSIXct('2021-03-01 00:00', tz="UTC"))
Target_30min_KONZ = subset(Target_30min, siteID == 'KONZ' & time >= as.POSIXct('2020-03-01 00:00', tz="UTC") & 
                                                                time < as.POSIXct('2021-03-01 00:00', tz="UTC"))
Target_30min_OSBS = subset(Target_30min, siteID == 'OSBS' & time >= as.POSIXct('2020-03-01 00:00', tz="UTC") & 
                                                                time < as.POSIXct('2021-03-01 00:00', tz="UTC"))
Target_30min_SRER = subset(Target_30min, siteID == 'SRER' & time >= as.POSIXct('2020-03-01 00:00', tz="UTC") & 
                                                                time < as.POSIXct('2021-03-01 00:00', tz="UTC"))


time_BART = Target_30min_BART$time
time_KONZ = Target_30min_KONZ$time
time_OSBS = Target_30min_OSBS$time
time_SRER = Target_30min_SRER$time

LE_BART = Target_30min_BART$le
LE_KONZ = Target_30min_KONZ$le
LE_OSBS = Target_30min_OSBS$le
LE_SRER = Target_30min_SRER$le

NEE_BART = Target_30min_BART$nee
NEE_KONTZ =Target_30min_KONZ$nee
NEE_OSBS =Target_30min_OSBS$nee
NEE_SRER =Target_30min_SRER$nee

VSWC_BART = Target_30min_BART$vswc
VSWC_KONTZ =Target_30min_KONZ$vswc
VSWC_OSBS =Target_30min_OSBS$vswc
VSWC_SRER =Target_30min_SRER$vswc


swlw_BART = subset(swlw, siteID == 'BART' & verticalPosition == '060' & 
                     startDateTime >= as.POSIXct('2020-03-01 00:00', tz="UTC") &
                     startDateTime < as.POSIXct('2021-03-01 00:00', tz="UTC"))

data_03B = data.frame(time = time_BART, LE_obs = LE_BART, NEE_obs = NEE_BART, VSWC_obs = VSWC_BART)
data_03B$insw = swlw_BART$inSWMean[match(data_03B$time,swlw_BART$startDateTime)]
data_03B$inlw = swlw_BART$inLWMean[match(data_03B$time,swlw_BART$startDateTime)]
data_03B$outlw = swlw_BART$outLWMean[match(data_03B$time,swlw_BART$startDateTime)]
```

```{r}
#remove NA's by replacing by mean...HOW TO DO THIS IN A NICE BAYESIAN WAY?

SW_BART = data_03B$insw
SW_BART[is.na(SW_BART)] <- mean(SW_BART, na.rm=TRUE)

LW_BART = data_03B$inlw
LW_BART[is.na(LW_BART)] <- mean(LW_BART, na.rm=TRUE)


```





```{r}
#Random Walk
JointDLM = "
model{
  
  #### Data Model
  for(t in 1:n){
    NEE_obs[t] ~ dnorm(NEE[t],tau_nee)
    LE_obs[t] ~ dnorm(LE[t],tau_le)
    VSWC_obs[t] ~ dnorm(VSWC[t],tau_vswc)
    #SW_obs[t] ~ dnorm(SW[t],tau_sw)
    #LW_obs[t] ~ dnorm(LW[t],tau_lw)
  }
  
  #### Process Model
  for(t in 2:n){
    NEE[t]~dnorm(a_NN * NEE[t-1] + a_NL*LE[t-1] + a_NV*VSWC[t-1] + a_NSW*SW[t] + a_NLW*LW[t],tau_nee_add)
    LE[t]~dnorm(a_LN * NEE[t-1] + a_LL*LE[t-1] + a_LV*VSWC[t-1] + a_LSW*SW[t] + a_LLW*LW[t],tau_le_add)
    VSWC[t]~dnorm(a_VN * NEE[t-1] + a_VL*LE[t-1] + a_VV*VSWC[t-1] + a_VSW*SW[t] + a_VLW*LW[t],tau_vswc_add)
  }
  
  #### Priors
  NEE[1] ~ dnorm(NEE_ic,tau_nee_ic)
  LE[1] ~ dnorm(LE_ic,tau_le_ic)
  VSWC[1] ~ dnorm(VSWC_ic,tau_vswc_ic)
  
  tau_nee ~ dgamma(1,.01)
  tau_le ~ dgamma(1,.01)
  tau_vswc ~ dgamma(1,.01)
  tau_sw ~ dgamma(1,.01)
  tau_lw ~ dgamma(1,.01)
  
  
 
  tau_nee_add ~ dgamma(1,1)
  tau_le_add ~ dgamma(1,1)
  tau_vswc_add ~ dgamma(1,1)
  
  a_NN ~ dgamma(1,1)
  a_NV ~ dnorm(0,1)
  a_NL ~ dnorm(0,1)
  
  a_LL ~ dgamma(1,1)
  a_LV ~ dnorm(0,1)
  a_LN ~ dnorm(0,1)
  
  a_VV ~ dgamma(1,1)
  a_VN ~ dnorm(0,1)
  a_VL ~ dnorm(0,1)
  
  a_NSW ~ dnorm(0,1)
  a_NLW ~ dnorm(0,1)
  
  a_LSW ~ dnorm(0,1)
  a_LLW ~ dnorm(0,1) 
  
  a_VSW ~ dnorm(0,1)
  a_VLW ~ dnorm(0,1)  
  

}
"

```

```{r}
NEE_init = 0
LE_init = 0
VSWC_init = 0

tau_NEE_init = 1
tau_LE_init = 1
tau_VSWC_init = 1



data_BART <- list(n=length(NEE_BART),
                  NEE_obs=NEE_BART,LE_obs=LE_BART,VSWC_obs=VSWC_BART,
                  SW = SW_BART,
                  LW = SW_BART,
                  NEE_ic= NEE_init,LE_ic= LE_init, VSWC_ic= VSWC_init, 
                  tau_nee_ic= tau_NEE_init,tau_le_ic= tau_LE_init, tau_vswc_ic= tau_VSWC_init)


```

```{r}
#Set inits 

#vswc
nchain = 3
init_BART <- list()

y_BART = NEE_BART 

y_BART = na.omit(y_BART)

for(i in 1:nchain){
  y.samp = sample(y_BART,length(y_BART),replace=TRUE)
  init_BART[[i]] <- list(tau_nee_add=1/var(diff(y.samp)),tau_nee=5/var(y.samp))
}
```

```{r}

#Now that we've defined the model, the data, and the initialization, we need to send all this info to JAGS, which will return the JAGS model object.

j.model_EC   <- jags.model (file = textConnection(JointDLM),
                            data = data_BART,
                            inits = init_BART,
                            n.chains = 3)

```

```{r}
names = c("tau_nee",
  "tau_le", 
  "tau_sw",
  "tau_lw", 
  "tau_nee_add",
  "tau_le_add",
  "tau_vswc_add",
  "a_NN",
  "a_NV",
  "a_NL",
  "a_LL",
  "a_LV",
  "a_LN", 
  "a_VV",
  "a_VN",
  "a_VL",
  "a_NSW",
  "a_NLW",
  "a_LSW",
  "a_LLW", 
  "a_VSW",
  "a_VLW")

```


```{r}
#MCMC diagnostics & Burn-in test
jags.out_BART <- coda.samples (model = j.model_EC,
                            variable.names = names,
                                n.iter = 1000)


plot(jags.out_BART)


```

```{r}
## Plot the model and data time series with interval estimates

#for BART
time1 = time_BART
time.rng = c(1,length(time1)) ## adjust to zoom in and out
out <- as.matrix(jags.out_BART)
LE.cols <- grep("^LE",colnames(out)) ## grab all columns that start with the letter x
ci2 <- apply(out[,LE.cols],2,quantile,c(0.025,0.5,0.975)) ## 
plot(time1,ci2[2,],type='n',ylim=range(LE_BART,na.rm=TRUE),ylab="BART LE",xlim=time1[time.rng])
## adjust x-axis label to be monthly if zoomed
if(diff(time.rng) < 100){
  axis.Date(1, at=seq(time1[time.rng[1]],time[time.rng[2]],by='month'), format = "%Y-%m")
}
ciEnvelope(time1,ci2[1,],ci2[3,],col=col.alpha("lightBlue",0.75))
points(time,LE_BART,pch="+",cex=0.5)



```



Below here is all the code from before trying to do the joint stuff.

```{r}

## fit the model ## It is quite time-consuming process (about 30~60 min.)
le_dynamic.out <- fit_dlm(model=list(obs="LE",fixed="~ 1 + X + insw + inlw",n.iter=10000,n.thin=10),data_03B)

```


```{r}
# burn-in test (covergence : OK / Gelman plot : >260 OK)
params <- le_dynamic.out$params
plot(params)
BGR_params <- gelman.plot(params)
BGR_params$shrink > 1.1
gelman.diag(params)
```

```{r}
# burn-in removal
params <- window(le_dynamic.out$params,start=260)
predict <- window(le_dynamic.out$predict,start=260)

summary(params)
cor(as.matrix(params))
pairs(as.matrix(params))
time = data_03B$time
time.rng = c(1,length(time))

newFilename <- sprintf("%s.Rdata","LE_BART_DLM")
newFilename <- paste(dataPath, newFilename, sep="", collapse = NULL)
save(params, predict, file = newFilename)

rm(swlw,le_dynamic.out,params,predict)

```

```{r}
## Plot the model and data time series with interval estimates

#for BART
# load the data file
newFilename <- sprintf("%s.jpg","LE_BART_modelplot_DLM")
newFilename <- paste(graphPath, newFilename, sep="", collapse = NULL)
loadFilename <- sprintf("%s.Rdata","LE_BART_DLM")
loadFilename <- paste(dataPath, loadFilename, sep="", collapse = NULL)
load(file = loadFilename)
time = time_BART
time.rng = c(1,length(time)) ## adjust to zoom in and out
out <- as.matrix(predict)
rm(params, predict)
x.cols <- grep("^x",colnames(out)) ## grab all columns that start with the letter x
ci <- apply(out[,x.cols],2,quantile,c(0.025,0.5,0.975)) ## 
jpeg(file = newFilename)
plot(time,ci[2,],type='n',ylim=range(le_BART,na.rm=TRUE),ylab="BART LE",xlim=time[time.rng])
## adjust x-axis label to be monthly if zoomed
if(diff(time.rng) < 100){
  axis.Date(1, at=seq(time[time.rng[1]],time[time.rng[2]],by='month'), format = "%Y-%m")
}
#ecoforecastR::ciEnvelope(time,ci[1,],ci[3,],col=ecoforecastR::col.alpha("lightBlue",0.75))
ciEnvelope(time,ci[1,],ci[3,],col=col.alpha("lightBlue",0.75))
points(time,le_BART,pch="+",cex=0.5)
dev.off()

rm(out)


```

```{r}

# Manipulate above code just freely #########################################
############################################### Below code is under revision

```


```{r}
#NOAA data load
# Download NOAA climate forecasts (hourly) and downsample to daily scale
source("00B_NOAAconversion.R")

for (S in site_names){
  download_noaa_files_s3(siteID = S, 
                         date = "2021-03-01", 
                         cycle = "00", 
                         local_directory <- paste0(basePath,"/drivers/"))
}
NOAA_Driver = noaa_gefs_read(paste0(basePath,"/drivers/noaa/NOAAGEFS_1hr"), "2021-03-01", "00", "BART")

predict_time = subset(NOAA_Driver, ensemble==1)
predict_time = predict_time$time

## Driver data conversion

sw_driver = subset(NOAA_Driver, ensemble!=0)
sw_driver = sw_driver$surface_downwelling_shortwave_flux_in_air
sw_driver = matrix(sw_driver, nrow=30 ,byrow = TRUE)

lw_driver = subset(NOAA_Driver, ensemble!=0)
lw_driver = lw_driver$surface_downwelling_longwave_flux_in_air
lw_driver = matrix(lw_driver, nrow=30 ,byrow = TRUE)

sw_driver_gf = matrix(0, nrow=30, ncol = 1681)
lw_driver_gf = matrix(0, nrow=30, ncol = 1681)

## filling gap (average)
for(i in 1:840){
  sw_driver_gf[,2*i-1]=sw_driver[,i]
  sw_driver_gf[,2*i]=(sw_driver[,i]+sw_driver[,i+1])/2
  lw_driver_gf[,2*i-1]=lw_driver[,i]
  lw_driver_gf[,2*i]=(lw_driver[,i]+lw_driver[,i+1])/2
}
sw_driver_gf[,1681]=sw_driver[,841]
lw_driver_gf[,1681]=lw_driver[,841]

```


```{r}

loadFilename <- sprintf("%s.Rdata","LE_BART_DLM")
loadFilename <- paste(dataPath, loadFilename, sep="", collapse = NULL)
load(file = loadFilename)

## Forward Simulation
### settings
Nmc = 1000         ## set number of Monte Carlo draws
N.cols <- c("red","green","blue") ## set colors
trans <- 0.8       ## set transparancy
time = 1:length(time_BART)+1681    ## total time (1yr + 35 days)
time1 = 1:length(time_BART)       ## calibration period
time2 = (length(time_BART)+1):(length(time_BART)+1681)   ## forecast period
timeN_predict = length(time2)
tmp = matrix(0,1,length(time))
ylim = c(-500,700)
```

```{r}
plot.run.nia <- function(limX = c(17000,17500), limY = c(-200,200)){
  plot(time,tmp,type='n',ylim=limY, xlim=limX,ylab="LE")
  #ecoforecastR::ciEnvelope(time1,ci[1,],ci[3,],col=col.alpha("lightBlue",0.6))
  ciEnvelope(time1,ci[1,],ci[3,],col=col.alpha("lightBlue",0.6))
  lines(time1,ci[2,],col="blue")
  points(time1,le_BART)
}
```



```{r}
plot.run <- function(){
  plot(time,tmp,type='n',ylim=ylim, ylab="LE")
  #ecoforecastR::ciEnvelope(time1,ci[1,],ci[3,],col=col.alpha("lightBlue",0.6))
  ciEnvelope(time1,ci[1,],ci[3,],col=col.alpha("lightBlue",0.6))
  lines(time1,ci[2,],col="blue")
  points(time1,le_BART)
}
```
```{r,echo=FALSE}
ci <- apply(as.matrix(predict),2,quantile,c(0.025,0.5,0.975))
plot.run.nia(limX=c(17100,17200), limY =c(-100,100))
plot.run()
```

```{r}
##` @param IC    Initial Conditions
##` @param r     Intrinsic growth rate
##` @param Kg    Across-site ('global') mean carrying capacity
##` @param alpha Site random effect
##` @param beta  Slope of precipitation effect on K
##` @param ppt   Precipitation forecast
##` @param Q     Process error (default = 0 for deterministic runs)
##` @param n     Size of Monte Carlo ensemble
forecastN <- function(IC,betaIntercept,betaX,betainlw,betainsw,sw,lw,Q=0,n=Nmc){
  N <- matrix(NA,n,timeN_predict)  ## storage
  Nprev <- IC           ## initialize
  for(t in 1:timeN_predict){
    mu = (1+betaX)*Nprev + betaIntercept + (betainsw*sw[,t]) + (betainlw*lw[,t])
    N[,t] <- rnorm(n,mu,Q)                         ## predict next step
    Nprev <- N[,t]                                  ## update IC
  }
  return(N)
}
```

```{r}

## calculate mean of all inputs
sw.mean <- matrix(apply(sw_driver_gf,2,mean),1,timeN_predict) ## driver
lw.mean <- matrix(apply(lw_driver_gf,2,mean),1,timeN_predict)
## parameters
params_mat <- as.matrix(params)
param.mean <- apply(params_mat,2,mean)
## initial conditions
IC <- as.matrix(predict)

##Deterministic prediction
N.det <- forecastN(IC=mean(IC[,"x[17520]"]),
                   betaIntercept=param.mean["betaIntercept"],
                   betaX=param.mean["betaX"],
                   betainlw=param.mean["betainlw"],
                   betainsw=param.mean["betainsw"],
                   sw=sw.mean,
                   lw=lw.mean,
                   Q=0,  ## process error off
                   n=1)

## Plot run
plot.run()
lines(time2,N.det,col="purple",lwd=3)

```

```{r}
## Monte Carlo Error Propagation
Nmc = 1000
#@ sample parameter rows from previous analysis
prow = sample.int(nrow(params_mat),Nmc,replace=TRUE)

N.I <- forecastN(IC=IC[prow,"x[17520]"],
                   betaIntercept=param.mean["betaIntercept"],
                   betaX=param.mean["betaX"],
                   betainlw=param.mean["betainlw"],
                   betainsw=param.mean["betainsw"],
                   sw=sw.mean,
                   lw=lw.mean,
                   Q=0,  ## process error off
                   n=Nmc)

## Plot run
plot.run()
N.I.ci = apply(N.I,2,quantile,c(0.025,0.5,0.975),na.rm=TRUE)
ecoforecastR::ciEnvelope(time2,N.I.ci[1,],N.I.ci[3,],col=col.alpha(N.cols[1],trans))
lines(time2,N.I.ci[2,],lwd=0.5)



```


```{r}
##Parameter Uncertainty

N.IP <- forecastN(IC=IC[prow,"x[17520]"],
                   betaIntercept=params_mat[prow,"betaIntercept"],
                   betaX=params_mat[prow,"betaX"],
                   betainlw=params_mat[prow,"betainlw"],
                   betainsw=params_mat[prow,"betainsw"],
                   sw=sw.mean,
                   lw=lw.mean,
                   Q=0,  ## process error off
                   n=Nmc)

## Plot run
plot.run()
N.IP.ci = apply(N.IP,2,quantile,c(0.025,0.5,0.975),na.rm=TRUE)
ecoforecastR::ciEnvelope(time2,N.IP.ci[1,],N.IP.ci[3,],col=col.alpha(N.cols[2],trans))
ecoforecastR::ciEnvelope(time2,N.I.ci[1,],N.I.ci[3,],col=col.alpha(N.cols[1],trans))
lines(time2,N.I.ci[2,],lwd=0.5)

```

```{r}
##Driver Uncertainty
#sample driver rows
drow_sw = sample.int(nrow(sw_driver_gf),Nmc,replace = TRUE)
drow_lw = sample.int(nrow(lw_driver_gf),Nmc,replace = TRUE)

N.IPD <- forecastN(IC=IC[prow,"x[17520]"],
                   betaIntercept=params_mat[prow,"betaIntercept"],
                   betaX=params_mat[prow,"betaX"],
                   betainlw=params_mat[prow,"betainlw"],
                   betainsw=params_mat[prow,"betainsw"],
                   sw=sw_driver_gf[drow_sw,],
                   lw=lw_driver_gf[drow_lw,],
                   Q=0,  ## process error off
                   n=Nmc)

## Plot run
plot.run()
N.IPD.ci = apply(N.IPD,2,quantile,c(0.025,0.5,0.975),na.rm=TRUE)
ecoforecastR::ciEnvelope(time2,N.IPD.ci[1,],N.IPD.ci[3,],col=col.alpha(N.cols[3],trans))
ecoforecastR::ciEnvelope(time2,N.IP.ci[1,],N.IP.ci[3,],col=col.alpha(N.cols[2],trans))
ecoforecastR::ciEnvelope(time2,N.I.ci[1,],N.I.ci[3,],col=col.alpha(N.cols[1],trans))
lines(time2,N.I.ci[2,],lwd=0.5)

```

```{r}
## process error samples
#Qmc <- 1/sqrt(params_mat[prow,"Q"])  ## convert from precision to standard deviation

#N.IPDE <- forecastN(IC=IC[prow,"x[17520]"],
#                   betaIntercept=params_mat[prow,"betaIntercept"],
#                   betaX=params_mat[prow,"betaX"],
#                   betainlw=params_mat[prow,"betainlw"],
#                   betainsw=params_mat[prow,"betainsw"],
#                   sw=sw_driver_gf[drow_sw,],
#                   lw=lw_driver_gf[drow_lw,],
#                   Q=Qmc,  ## process error off
#                   n=Nmc)

## Plot run
#plot.run()
#N.IPDE.ci = apply(N.IPDE,2,quantile,c(0.025,0.5,0.975))
#ecoforecastR::ciEnvelope(time2,N.IPDE.ci[1,],N.IPDE.ci[3,],col=col.alpha(N.cols[4],trans))
#ecoforecastR::ciEnvelope(time2,N.IPD.ci[1,],N.IPD.ci[3,],col=col.alpha(N.cols[3],trans))
#ecoforecastR::ciEnvelope(time2,N.IP.ci[1,],N.IP.ci[3,],col=col.alpha(N.cols[2],trans))
#ecoforecastR::ciEnvelope(time2,N.I.ci[1,],N.I.ci[3,],col=col.alpha(N.cols[1],trans))
#lines(time2,N.I.ci[2,],lwd=0.5)
```

```{r}
## Random effect samples
#tau.mc <- 1/sqrt(params_mat[prow,"tau_site"]) ## convert from precision to std deviation
#aNew.mc <- rnorm(Nmc,0,tau.mc)            ## draw out-of-sample predictions of alpha at a new site

#N.IPDEA <- forecastN(IC=IC[prow,"x[17520]"],
#                   betaIntercept=params_mat[prow,"betaIntercept"],
#                   betaX=params_mat[prow,"betaX"],
#                   betainlw=params_mat[prow,"betainlw"],
#                   betainsw=params_mat[prow,"betainsw"],
#                   sw=sw_driver_gf[drow_sw,],
#                   lw=lw_driver_gf[drow_lw,],
#                   alpha=aNew.mc,
#                   Q=Qmc,  ## process error off
#                   n=Nmc)

## Plot run
#plot.run()
#N.IPDEA.ci = apply(N.IPDEA,2,quantile,c(0.025,0.5,0.975))
#ecoforecastR::ciEnvelope(time2,N.IPDEA.ci[1,],N.IPDEA.ci[3,],col=col.alpha(N.cols[5],trans))
#ecoforecastR::ciEnvelope(time2,N.IPDE.ci[1,],N.IPDE.ci[3,],col=col.alpha(N.cols[4],trans))
#ecoforecastR::ciEnvelope(time2,N.IPD.ci[1,],N.IPD.ci[3,],col=col.alpha(N.cols[3],trans))
#ecoforecastR::ciEnvelope(time2,N.IP.ci[1,],N.IP.ci[3,],col=col.alpha(N.cols[2],trans))
#ecoforecastR::ciEnvelope(time2,N.I.ci[1,],N.I.ci[3,],col=col.alpha(N.cols[1],trans))
#lines(time2,N.I.ci[2,],lwd=0.5)
```

```{r}
### calculation of variances
varI     <- apply(N.I,2,var)
varIP    <- apply(N.IP,2,var)
varIPD   <- apply(N.IPD,2,var)
#varIPDE  <- apply(N.IPDE,2,var)
#varIPDEA <- apply(N.IPDEA,2,var)
varMat   <- rbind(varI,varIP,varIPD)

## out-of-sample stacked area plot
V.pred.rel <- apply(varMat,2,function(x) {x/max(x)})
plot(time2,V.pred.rel[1,],ylim=c(0,1),type='n',main="Relative Variance: Out-of-Sample",ylab="Proportion of Variance",xlab="time")
ciEnvelope(time2,rep(0,ncol(V.pred.rel)),V.pred.rel[1,],col=N.cols[1])
ciEnvelope(time2,V.pred.rel[1,],V.pred.rel[2,],col=N.cols[2])
ciEnvelope(time2,V.pred.rel[2,],V.pred.rel[3,],col=N.cols[3])
ciEnvelope(time2,V.pred.rel[3,],V.pred.rel[3,],col=N.cols[3])
#ciEnvelope(time2,V.pred.rel[4,],V.pred.rel[5,],col=N.cols[5])
legend("topright",legend=c("Driver","Parameter","InitCond"),col=rev(N.cols),lty=1,lwd=3)

## in-sample stacked area plot
#V.pred.rel.in <- apply(varMat[-5,],2,function(x) {x/max(x)})
#plot(time2,V.pred.rel.in[1,],ylim=c(0,1),type='n',main="Relative Variance: In-Sample",ylab="Proportion of Variance",xlab="time")
#ciEnvelope(time2,rep(0,ncol(V.pred.rel.in)),V.pred.rel.in[1,],col=N.cols[1])
#ciEnvelope(time2,V.pred.rel.in[1,],V.pred.rel.in[2,],col=N.cols[2])
#ciEnvelope(time2,V.pred.rel.in[2,],V.pred.rel.in[3,],col=N.cols[3])
#ciEnvelope(time2,V.pred.rel.in[3,],V.pred.rel.in[4,],col=N.cols[4])
#legend("topright",legend=c("Driver","Parameter","InitCond"),col=rev(N.cols[-5]),lty=1,lwd=5)
```
